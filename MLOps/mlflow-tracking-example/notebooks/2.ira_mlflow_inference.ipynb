{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import mlflow.pytorch\n",
    "import torchvision.transforms as transforms\n",
    "from medmnist import PathMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import mlflow\n",
    "\n",
    "\n",
    "# Load the trained model from MLFlow\n",
    "def load_model_from_mlflow(model_uri):\n",
    "    # Load the trained model\n",
    "    print(f\"Loading model from {model_uri}\")\n",
    "    model = mlflow.pytorch.load_model(model_uri)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data (PathMNIST dataset in this case)\n",
    "def load_test_data(batch_size):\n",
    "    # Define the data transformations (normalization is the same as used in training)\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "\n",
    "    # Load PathMNIST test dataset\n",
    "    test_dataset = PathMNIST(split='test', transform=data_transform, download=True, root = \"../data/raw\")\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run inference on the test data\n",
    "def run_inference(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:  # We ignore the labels during inference\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the inference results to MLFlow\n",
    "def log_inference_results(predictions):\n",
    "    # Log predictions to MLFlow\n",
    "    for i, pred in enumerate(predictions):\n",
    "        mlflow.log_metric(f\"prediction_{i}\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"adca5b681fb54667a3b5e82114034130\"\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanrs/opt/anaconda3/envs/micai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from runs:/adca5b681fb54667a3b5e82114034130/PathMNIST_cnn_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 6/6 [00:00<00:00, 16.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/raw/pathmnist.npz\n"
     ]
    }
   ],
   "source": [
    "# Load the model from MLFlow (use the model URI stored during training)\n",
    "model_uri = f\"runs:/{run_id}/PathMNIST_cnn_model\"  # Replace <RUN_ID> with your actual run ID\n",
    "model = load_model_from_mlflow(model_uri)\n",
    "\n",
    "# Set the batch size for testing\n",
    "batch_size = 64\n",
    "\n",
    "# Load the test data\n",
    "test_loader = load_test_data(batch_size)\n",
    "\n",
    "# Run inference\n",
    "predictions = run_inference(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 4, 0, 8, 4, 0, 8, 0, 4, 8]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
